<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>BLOG</title>

  <link rel="shortcut icon" href="../assets/images/logo.png" type="image/x-icon">

  <link rel="stylesheet" href="https://unpkg.com/kursor/dist/kursor.css">
  <script src="https://cdn.jsdelivr.net/npm/kursor@0.0.14/dist/kursor.js"></script>

  <link rel="stylesheet" href="../assets/css/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;700&display=swap">


</head>

<body>


  <!-- Assets -->
  <button id="scrollTopButton" class="scroll-button scroll-top">
    <img src="../assets/images/sidebar/chevron-angle-svgrepo-com.svg" alt="design icon" width="40">

  </button>

  <button id="scrollBottomButton" class="scroll-button scroll-bottom">
    <img src="../assets/images/sidebar//down-arrow-download-svgrepo-com.svg" alt="design icon" width="40">

  </button>

  <audio id="clickSound">
    <source src="../assets/images/aud/sound.wav" type="audio/wav">
    Your browser does not support the audio element.
  </audio>

  <div class="video-container">
    <video autoplay loop muted id="background-video">
      <source src="../assets/images/video/bg2.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
  </div>

  <!-- #MAIN -->
  <main>

    <!-- #SIDEBAR -->
    <aside class="sidebar" data-sidebar>
      <div class="sidebar-info">

        <figure class="avatar-box">
          <img class=" test-shine" src="../assets/images/tushararora1.png" alt="tushar arora" width="80">
        </figure>

        <div class="info-content">


          <div class="waviy">
            <span style="--i:1">2</span>
            <span style="--i:2">4</span>
            <span style="--i:3">X</span>
            <span style="--i:4">7</span>
            <span style="--i:5">-</span>
            <span style="--i:6">D</span>
            <span style="--i:7">E</span>
            <span style="--i:8">V</span>
            <span style="--i:9">-</span>
            <span style="--i:10">P</span>
            <span style="--i:11">L</span>
            <span style="--i:12">A</span>
            <span style="--i:13">Y</span>
            <span style="--i:14">E</span>
            <span style="--i:15">R</span>
          </div>

          <div style="display: flex; 
          justify-content: center; ">
            <div id="badge-container" style="display: inline-block;"></div>
          </div>

        </div>

        <button class="info_more-btn" data-sidebar-btn>
          <span>Show Contacts</span>

          <ion-icon name="chevron-down"></ion-icon>
        </button>

      </div>

      <div class="sidebar-info_more">
        <div class="separator"></div>
        <ul class="contacts-list">

          <li class="contact-item">
            <div class="service-icon-box">
              <img src="../assets/images/sidebar/mailsvg.svg" alt="design icon" width="30">
            </div>
            <div class="contact-info">
              <p class="contact-title">Email</p>
              <a href="mailto:tushar.aka.datascientist@gmail.com"
                class="contact-link">Tushar.aka.datascientist@gmail.com</a>
            </div>
          </li>

          <li class="contact-item">
            <div class="service-icon-box">
              <img src="../assets/images/sidebar/phonesvg.svg" alt="design icon" width="30">
            </div>
            <div class="contact-info">
              <p class="contact-title">Phone</p>
              <a href="tel:+12133522795" class="contact-link">+91 <span>&#8730;</span>78341703057303861904</a>
            </div>
          </li>

          <li class="contact-item">
            <div class="service-icon-box">
              <img src="../assets/images/sidebar/age.svg" alt="design icon" width="30">
            </div>
            <div class="contact-info">
              <p class="contact-title">AGE</p>
              <a href="#" class="contact-link"><span id="age"></span></a>
            </div>
          </li>

          <li class="contact-item">
            <div class="service-icon-box">
              <img src="../assets/images/sidebar/map.svg" alt="design icon" width="30">
            </div>
            <div class="contact-info">
              <p class="contact-title">Location</p>
              <a href="#" class="contact-link">28¬∞44'29.6"N 77¬∞17'01.8"E</a>
            </div>
          </li>

        </ul>

        <div class="separator"></div>

        <ul class="social-list">

          <li class="social-item">
            <a href="https://github.com/24x7-Dev-Player" target="_blank" class="social-link">
              <img src="../assets/images/sidebar/github.svg" alt="design icon" width="40">

            </a>
          </li>

          <li class="social-item">
            <a href="https://wa.me/918851084852" target="_blank" class="social-link">
              <img src="../assets/images/sidebar/whatsapp.svg" alt="design icon" width="40">

            </a>
          </li>

          <li class="social-item">
            <a href="https://www.linkedin.com/in/tushar-perspective" target="_blank" class="social-link">
              <img src="../assets/images/sidebar/linkedin.svg" alt="design icon" width="40">

            </a>
          </li>

          <li class="social-item">
            <a href="https://www.instagram.com/tushar.oclock" target="_blank" class="social-link">
              <img src="../assets/images/sidebar/instagram.svg" alt="design icon" width="40">

            </a>
          </li>


        </ul>

      </div>

    </aside>


    <!-- #main-content -->
    <div class="main-content">


      <!-- NAVBAR -->
      <nav class="navbar">
        <ul class="navbar-list">
          <li class="navbar-item">
            <button style="font-size: 40px;" class="navbar-link"
              onclick="window.open('https://24x7-dev-player.github.io/Portfolio/', '_blank')">üè°</button>
          </li>
        </ul>
      </nav>



      <!-- BLOG -->
      <article class="about  active" data-page="about">

        <header>
          <h2 class="h2 article-title">üìõ Unsupervised Learning</h2>
        </header>

        <div class="blog">
          <ul>
            <li style="color: lightsalmon; text-align: justify; ">
              ‚óè Introduction ‚óè K-mean Clustering ‚óè Find K code Example ‚óè Types ‚óè K mean from Scratch ‚óè DBSCAN ‚óè
              Hierarchical Clustring ‚óè Gaussian Mixture Models
            </li>
          </ul>
        </div> <br>

        <section class="about-text with-line">
        </section>

        <section class="about-text">

          <h3 class="h3 service-title">üöÄ Introduction:</h3>
          <div class="blog">
            <ul>
              <li><strong> Unsupervised Leanring</strong>: Clustering, Association, Dimenionality reducation, Anomaly
                detection, Language model</li>
              <li> <strong>Application of Clustering</strong>: Customer Segmentation, Data analysis, Semi Supervised
                learning, Image Segmentation </li>
              <li><strong>Types</strong>: Partitional, Hierarchical, Density based, Distribution, Graph based, Soft vs
                Hard </li>


            </ul>

          </div> <br>

          <h3 class="h3 service-title">üöÄ K-Mean Clustering:</h3>
          <div class="blog">
            <ul>
              <li><strong> Process</strong>: Decide k, Initialize centroids, start iteration, Assign cluster, move
                centroid, check & stop</li>
              <li> <strong>Matrix</strong>: Intra cluster, inter cluster & Dunn Index </li>
              <li><strong>Hyperparameter</strong>: K choose by Elbow method & Silhouette Score(Cohesion),
                Initializaation Method, n_init, max_iter, tol </li>
              <li><strong>Assumption</strong>: Spherical Cluster Shape, Similar Cluster SIze, Equal Varience, Well
                seperated, Must large number of data points and less k, Define K form Starting</li>
              <li><strong>Limitation</strong>: Required Cluster of Similar size, Similar varience between cluster,
                Assumption in Spherical cluster, Vulnerablity of outlier, Hard clustering, High dimensionality
                challenges, Sensitive to scale </li>
              <li><strong>Updated version</strong>: Kmean++, K-medoids, lloyd & Elkan Algorithm, Mini Batch K mean</li>


            </ul>

          </div> <br>

          <h3 class="h3 service-title">üöÄFind K Code Example:</h3>
          <div class="code-window">
            <pre>
              #Elbow Method
              from sklearn.cluster import KMeans
              wcss = []
              for i in range(1, 11):
                  kmeans = KMeans(n_init = 10, n_clusters = i)
                  kmeans.fit(X)
                  wcss.append(kmeans.inertia_)

              # Silhouette Score
              from sklearn.metrics import silhouette_score
              sil = []
              for i in range(2, 11):
                  kmeans = KMeans(n_clusters=i)
                  cluster_labels = kmeans.fit_predict(X)
                  silhouette_avg = silhouette_score(X, cluster_labels)
                  sil.append(silhouette_avg)
            </pre>
          </div> <br>

          <h3 class="h3 service-title">üöÄ Types:</h3>
          <div class="blog">
            <ul>
              <li><strong> Partitional Clustering</strong>: K means, Define no. of k, iterative Process, Objective
                function, work on certain dataset, handling outliers, initial condition, Scalalbility & efficiency, not
                work on varing cluster or noicy data</li>
              <li><strong>Hierarchical Clustering</strong>: Agglomerative & divisive, No need to specify Cluster,
                Dendogram, Use diffrent matrix, flexibility in shape, computation cost, sensitvity noice and outlier,
                Application in NLP, biology, etc. </li>
              <li><strong>Density Based</strong>: DBSCAN, No need to specify clsuter, Handling noice and outliers,
                Arbitery Shape, Parameter sensitvity, Scalability</li>
              <li><strong>Distribution</strong>:Gaussian based, Handling complex cluater shape, Computation intensity,
                Parameter Estimation, Handling outliers, Scalability, Soft Clustering</li>


            </ul>

          </div> <br>

          <h3 class="h3 service-title">üöÄK mean from Scratch:</h3>
          <div class="code-window">
            <pre>
              import random
              import numpy as np
              
              class KMeans:
                  def __init__(self, n_clusters=2, max_iter=100):
                      self.n_clusters = n_clusters  # Number of clusters
                      self.max_iter = max_iter      # Maximum number of iterations
                      self.centroids = None         # To store the centroids
              
                  def fit_predict(self, X):
                      # Randomly initialize centroids from the dataset
                      random_index = random.sample(range(0, X.shape[0]), self.n_clusters)
                      self.centroids = X[random_index]
              
                      for i in range(self.max_iter):
                          # Assign clusters to each data point
                          cluster_group = self.assign_clusters(X)
                          old_centroids = self.centroids
                          # Move centroids to the mean of their assigned points
                          self.centroids = self.move_centroids(X, cluster_group)
                          # Check if centroids have changed, if not, stop the algorithm
                          if (old_centroids == self.centroids).all():
                              break
              
                      return cluster_group
              
                  def assign_clusters(self, X):
                      cluster_group = []  # To store the index of the closest centroid for each point
                      distances = []      # To store the distances of each point to the centroids
              
                      for row in X:
                          for centroid in self.centroids:
                              # Calculate Euclidean distance between point and centroid
                              distances.append(np.sqrt(np.dot(row - centroid, row - centroid)))
                          # Find the closest centroid
                          min_distance = min(distances)
                          index_pos = distances.index(min_distance)
                          cluster_group.append(index_pos)
                          distances.clear()  # Clear distances for the next point
              
                      return np.array(cluster_group)
              
                  def move_centroids(self, X, cluster_group):
                      new_centroids = []  # To store the new centroids
              
                      cluster_type = np.unique(cluster_group)  # Unique cluster indices
              
                      for type in cluster_type:
                          # Calculate the mean of points in each cluster to find the new centroid
                          new_centroids.append(X[cluster_group == type].mean(axis=0))
              
                      return np.array(new_centroids)
            </pre>
          </div> <br>
        </section>

        <h3 class="h3 service-title">üöÄ DBSCAN:</h3>
        <div class="blog">
          <ul>
            <li><strong>Density Based Algorithm</strong>: DBSCAN and OPTICS</li>
            <li><strong>Key Concepts</strong>: Minpts & Epsilon, Core, Border, Noice Points, Density Connected points,
              Direct Density Reachable </li>
            <li><strong>Hyperparameter</strong>: Eps & MinPts</li>
            <li><strong>Advantages</strong>: Robust to outliers, No need to specify cluster, Can find Arbitery shape,
              Only 2 Hyperparameter </li>
            <li><strong>Limitation</strong>: Sensitivity, Difficult in varying shape</li>
            <li><strong>Application areas</strong>: Geography data, Anomaly, Image processing, bioinformative,
              Astronomy, Traffic analysis, Data mining, Social network, Customer Segmentation</li>
          </ul>
        </div> <br>

        <div class="code-window">
          <pre>
            import numpy as np
            import matplotlib.pyplot as plt
            from sklearn.cluster import DBSCAN
            from sklearn import datasets
            from sklearn.preprocessing import StandardScaler
            
            # Load the Iris dataset
            iris = datasets.load_iris()
            X = iris.data
            
            # Standardize the features
            X = StandardScaler().fit_transform(X)
            
            # Compute DBSCAN
            db = DBSCAN(eps=0.5, min_samples=5).fit(X)
            labels = db.labels_
            
            # Number of clusters in labels, ignoring noise if present
            n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)
            
            print(f'Estimated number of clusters: {n_clusters_}')
            
            # Plotting the results
            unique_labels = set(labels)
            colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]
            for k, col in zip(unique_labels, colors):
                if k == -1:
                    # Black used for noise.
                    col = [0, 0, 0, 1]
            
                class_member_mask = (labels == k)
            
                xy = X[class_member_mask]
                plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col), markeredgecolor='k', markersize=6)
            
            plt.title(f'Estimated number of clusters: {n_clusters_}')
            plt.show()              
          </pre>
        </div> <br>

        <h3 class="h3 service-title">üöÄ Hierarchical Clustring:</h3>
        <div class="blog">
          <ul>
            <li><strong>Agglomerative</strong>: Initial step, Clustering Process, Dendogram, Bottom-up Approach</li>
            <li><strong>Divisive</strong>: Initial steps, Clustering process, Top-Down apprach.
            <li><strong>Alogorithm</strong>: Initialization, Compute distance Matrix, Find the closest, Merge Cluster,
              Update Distance Matrix, Repeat</li>
          </ul>
          <li><strong>Concepts</strong>: linkage, Proximity</li>
          <li><strong>Find number of Clusters</strong>: Dendogram</li>
          <li><strong>Linkage</strong>: Hyperparametr, Min(Single Linkage), Max(Complete Linkage), Average Method, Ward Method</li>
          <li><strong>Advantages</strong>:hierarchy, Any diatance, Robust to outlier & Noice, Easy to understand</li>
          <li><strong>Disadvantages</strong>: No methamatical objective, Complexity,  Not available for large datatset, Linkage Criteria</li>
        </div> <br>

        <div class="code-window">
          <pre>
            import numpy as np
            import matplotlib.pyplot as plt
            from scipy.cluster.hierarchy import dendrogram, linkage
            from scipy.cluster.hierarchy import fcluster
            
            # Sample data: replace this with your own data
            np.random.seed(0)
            data = np.random.rand(10, 2)  # 10 points in 2D space
            
            # Perform hierarchical clustering using the 'ward' method
            Z = linkage(data, method='ward')
            
            # Create a dendrogram to visualize the clustering
            plt.figure(figsize=(10, 7))
            dendrogram(Z, labels=np.arange(1, 11))
            plt.title('Hierarchical Clustering Dendrogram')
            plt.xlabel('Sample index')
            plt.ylabel('Distance')
            plt.show()
            
            # Apply hierarchical clustering and retrieve cluster labels
            # Use a distance threshold to form flat clusters (for example, threshold=0.7)
            max_d = 0.7
            clusters = fcluster(Z, max_d, criterion='distance')
            
            print(f'Cluster assignments: {clusters}')
        </pre>
        </div> <br>


        <h3 class="h3 service-title">üöÄ Gaussian Mixture Models:</h3>
        <div class="blog">
          <ul>
            <li><strong>Key Concepts</strong>: Model based Clustering, EM Algorithm, KDE, Soft vs Hard,  </li>
            <li><strong>Covarience Type</strong>: Spherical, Diagonal, Tied, Full</li>
            <li><strong>Hyperparameter</strong>: Covarience type, Decide N Component (AIC & BIC) </li>
        </div> <br>

        <div class="code-window">
          <pre>
            import numpy as np
            import matplotlib.pyplot as plt
            from sklearn.datasets import make_blobs
            from sklearn.mixture import GaussianMixture
            
            # Create sample data
            n_samples = 500
            random_state = 42
            X, y_true = make_blobs(n_samples=n_samples, centers=3, cluster_std=0.60, random_state=random_state)
            
            # Visualize the sample data
            plt.scatter(X[:, 0], X[:, 1], s=15)
            plt.title("Sample Data")
            plt.xlabel("Feature 1")
            plt.ylabel("Feature 2")
            plt.show()
            
            # Fit a Gaussian Mixture Model
            gmm = GaussianMixture(n_components=3, random_state=random_state)
            gmm.fit(X)
            
            # Predict cluster labels
            labels = gmm.predict(X)
            
            # Plot the clustered data
            plt.scatter(X[:, 0], X[:, 1], c=labels, s=15, cmap='viridis')
            plt.title("GMM Clustering")
            plt.xlabel("Feature 1")
            plt.ylabel("Feature 2")
            plt.show()
            
            # Print the means of the clusters
            print("Cluster means:\n", gmm.means_)
            
            # Optional: Plot the ellipses representing the Gaussian components
            def plot_gmm(gmm, X, label=True, ax=None):
                ax = ax or plt.gca()
                labels = gmm.fit_predict(X)
                if label:
                    ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)
                else:
                    ax.scatter(X[:, 0], X[:, 1], s=40, zorder=2)
                ax.axis('equal')
                
                w_factor = 0.2 / gmm.weights_.max()
                for pos, covar, w in zip(gmm.means_, gmm.covariances_, gmm.weights_):
                    draw_ellipse(pos, covar, alpha=w * w_factor)
            
            def draw_ellipse(position, covariance, ax=None, **kwargs):
                ax = ax or plt.gca()
                if covariance.shape == (2, 2):
                    U, s, Vt = np.linalg.svd(covariance)
                    angle = np.degrees(np.arctan2(U[1, 0], U[0, 0]))
                    width, height = 2 * np.sqrt(s)
                else:
                    angle = 0
                    width, height = 2 * np.sqrt(covariance)
                for nsig in range(1, 4):
                    ax.add_patch(plt.Ellipse(position, nsig * width, nsig * height, angle, **kwargs))
            
            plt.figure(figsize=(8, 6))
            plot_gmm(gmm, X)
            plt.title("GMM with Ellipses Representing Gaussian Components")
            plt.xlabel("Feature 1")
            plt.ylabel("Feature 2")
            plt.show()
            
        </pre>
        </div> <br>





      </article>
    </div>




  </main>
  <script type="module" src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.esm.js"></script>
  <script nomodule src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.js"></script>
  <script src="blogs.js"></script>

</body>

</html>